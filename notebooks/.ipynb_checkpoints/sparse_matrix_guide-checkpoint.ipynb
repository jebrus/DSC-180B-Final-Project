{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779ad2aa-2cfa-404c-9163-ac69c1b48e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9727a5a6-ab1e-44a9-8a93-b19d673cfabf",
   "metadata": {},
   "source": [
    "The one-hot encoded version of the user data is saved as a Scipy sparse matrix. Feel free to perform EDA on the DataFrame version, but for training we'll need this one. Here I'll provide a very brief explanation of how sparse matrices work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b39adb9-5b6b-43ed-ac7c-9793144c1f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.read_csv('../data/filtered_user_df.csv')\n",
    "sparse_matrix = scipy.sparse.load_npz('../data/user_data.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be300fd2-96ab-4f87-849c-298c7c6d617d",
   "metadata": {},
   "source": [
    "Sparse matrices store information as indices, minimizing the amount of storage needed. As such, we can have a massive one-hot encoded matrix that we ordinarily would need hundreds of gigabytes to store. However, we need a way to convert the indices in the matrix back to meaningful information, as well as a way to convert data into indices to interact with the matrix. We define those mappings below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa34395d-4fb2-4578-8c49-ca8c547a07c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = user_df['user'].unique()\n",
    "artist_names = user_df['artist_name'].unique()\n",
    "\n",
    "user_to_index = {user: i for i, user in enumerate(user_ids)}\n",
    "artist_to_index = {artist: j for j, artist in enumerate(artist_names)}\n",
    "\n",
    "index_to_user = {i: user for user, i in user_to_index.items()}\n",
    "index_to_artist = {j: artist for artist, j in artist_to_index.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030fd4a1-060a-4832-a35a-117fdb7b440b",
   "metadata": {},
   "source": [
    "To demonstrate how these mappings can be used, let's take a look at a function that retrieves a user's play counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19132d87-df8b-401c-8eac-11b02a557854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_play_ct(user):  # The username you want to query\n",
    "    # Map the username to its index in the matrix\n",
    "    user_index = user_to_index[user]\n",
    "\n",
    "    # Pull the row at the user index in the matrix\n",
    "    user_play_counts = sparse_matrix.getrow(user_index)\n",
    "\n",
    "    # To convert to a dense format (non-sparse)\n",
    "    user_play_counts_dense = user_play_counts.todense()\n",
    "    \n",
    "    return pd.Series(user_play_counts_dense.A1, artist_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f1acc34-996c-494f-9a4d-de8f30d30ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jasmine Thompson                 7559\n",
       "Eminem                           5851\n",
       "Watsky                           3044\n",
       "Linkin Park                      2938\n",
       "twenty one pilots                1849\n",
       "                                 ... \n",
       "Ray Conniff and His Orchestra       0\n",
       "Dorit Chrysler                      0\n",
       "Skintone                            0\n",
       "Royale                              0\n",
       "DJ Stickle                          0\n",
       "Length: 97310, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_play_ct('nyancrimew')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de423dc1-34d3-4515-822c-09a6e562ec97",
   "metadata": {},
   "source": [
    "While the sparseness of this matrix makes it great for training a model, it's not so easy to perform EDA on. As such, **please use the DataFrame version of the data instead (filtered_user_df.csv)!** However, when training a model, this should be your go-to."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
