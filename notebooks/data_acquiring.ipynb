{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0fea0ee-f1e3-4e09-9650-0845f19fc13c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import requests\n",
    "import json\n",
    "import copy\n",
    "import random\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae078da-fdc4-4c0d-bfa4-0fe7119ae99b",
   "metadata": {},
   "source": [
    "For this prediction task, we require two datasets. First, we need a list of the top artists of users in order to make predictions. This information will be used to train our recommender system. The other is a list of the nationalities of each artist within our recommender system. This will be used to debias our model. \n",
    "\n",
    "We'll start with the top artists list. We'll obtain this via the Last.fm API. The following code logs into the API and enables us to pull the relevant data via Python. For information on how to set up a Last.fm  API account, follow [this link](https://www.last.fm/api) for documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e5bcf78-1ca2-47e1-acfa-85ec0ea883e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in key and secret from file\n",
    "with open('../lastfm.key', 'r') as keys:\n",
    "    key = keys.readline().strip()\n",
    "    secret = keys.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d105004-1b05-4071-8a53-824b422685c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pull access token from Last.fm\n",
    "token_request = requests.get(f'http://ws.audioscrobbler.com/2.0/?method=auth.gettoken&api_key={key}&format=json',)\n",
    "token = json.loads(token_request.text)['token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e0da86e-be3a-426d-9614-79f3f58f60b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.last.fm/api/auth/?api_key=6353b7f632a9fd6487aa7093cf57084f&token=BQMJwPmSUd8b88EAawZToZh5IjOu9ujG'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Approval link (follow this and approve manually every time you generate a token)\n",
    "f'http://www.last.fm/api/auth/?api_key={key}&token={token}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cc937fc-9b3f-467a-b6a6-3156af0c4c10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Signature: c240e5fa7e2c736b5bf56e398b219589\n"
     ]
    }
   ],
   "source": [
    "# Combine our key, secret, and access token to generate an API signature\n",
    "# This is needed for our requests to be approved\n",
    "import hashlib\n",
    "\n",
    "def generate_api_signature(api_key, method, token, shared_secret):\n",
    "    # Create a dictionary of parameters\n",
    "    params = {\n",
    "        'api_key': api_key,\n",
    "        'method': method,\n",
    "        'token': token\n",
    "    }\n",
    "\n",
    "    # Sort the parameters alphabetically by key\n",
    "    sorted_params = sorted(params.items())\n",
    "\n",
    "    # Concatenate the sorted parameters\n",
    "    concatenated = ''.join('%s%s' % (key, value) for key, value in sorted_params)\n",
    "\n",
    "    # Append the shared secret\n",
    "    string_to_hash = concatenated + shared_secret\n",
    "\n",
    "    # Generate the MD5 hash of the string\n",
    "    api_sig = hashlib.md5(string_to_hash.encode('utf-8')).hexdigest()\n",
    "\n",
    "    return api_sig\n",
    "\n",
    "# Usage example\n",
    "api_key = key\n",
    "method = 'auth.getSession'\n",
    "token = token\n",
    "shared_secret = secret\n",
    "\n",
    "api_signature = generate_api_signature(api_key, method, token, shared_secret)\n",
    "print(\"API Signature:\", api_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5387ba2-e595-4a15-9914-0c6eac36f91b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use our API signature to acquire our session key\n",
    "sesh = requests.get(f'http://ws.audioscrobbler.com/2.0/?method=auth.getSession&api_key={key}&token={token}&api_sig={api_signature}&format=json').text\n",
    "sk = sesh['session']['key']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a04c3f-76e4-4289-95a8-701ee3486617",
   "metadata": {},
   "source": [
    "Now we can pull our data. There is no publicly available Last.fm username dataset, and the only function the API has to get a list of users is user.getFriends, which returns the friends of a specified user. We can use this to generate a dataset of usernames by pulling a user's friends, and then their friends' friends, and so on and so forth. This requires us to specify a starting user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b466a5d2-2a5d-4e47-b939-db28c426fc11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "starting_user = '' # Replace this with the username of the user you want to start scraping from\n",
    "seen_users = set(users.keys())\n",
    "next_user_queue = [starting_user]\n",
    "current_user = next_user_queue.pop()\n",
    "while current_user in seen_users:\n",
    "    current_user = next_user_queue.pop()\n",
    "\n",
    "for i in range(5000):\n",
    "    print(current_user)\n",
    "    last_pg_hit = False\n",
    "    current_page = 1\n",
    "    while not last_pg_hit:\n",
    "        try:\n",
    "            user_friends = requests.get(f'http://ws.audioscrobbler.com/2.0/?method=user.getfriends&user={current_user}&api_key={key}&format=json&page={current_page}').text\n",
    "            friends_dict = json.loads(user_friends)['friends']['user']\n",
    "            friends_list = [friend['name'] for friend in friends_dict]\n",
    "            if current_user not in users:\n",
    "                users[current_user] = friends_list\n",
    "            else:\n",
    "                users[current_user] += friends_list\n",
    "            random.shuffle(friends_list)\n",
    "            next_user_queue += friends_list\n",
    "            current_page += 1\n",
    "        except KeyError:\n",
    "            last_pg_hit = True\n",
    "            seen_users.add(current_user)\n",
    "            while current_user in seen_users:\n",
    "                current_user = next_user_queue.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5216a5d-463e-4301-89ea-b9d6a7dbab83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set of all users in the dataset\n",
    "all_users = set()\n",
    "for lst in users.values():\n",
    "    for user in lst:\n",
    "        all_users.add(user)\n",
    "len(all_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebbe664-e71e-401e-88f2-d696056c1334",
   "metadata": {},
   "source": [
    "By now, we've pulled all our usernames, but we don't have any information on the artists the users like. We will now use the API's user.getTopArtists method to pull that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1055ca54-7215-4de1-9bbf-7f7a680f9c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.DataFrame(columns=['user', 'artist_name', 'play_count', 'artist_url'])\n",
    "df_user_set = set(user_df['user'])\n",
    "print('df read.')\n",
    "rows_to_add = []\n",
    "\n",
    "for current_user in all_users:\n",
    "    if current_user not in df_user_set and current_user not in no_artist_users:\n",
    "        print(current_user)\n",
    "        try:\n",
    "            sleep(0.2) # Follow last.fm regulations on rate limits\n",
    "            user_tops = json.loads(requests.get(f'http://ws.audioscrobbler.com/2.0/?method=user.gettopartists&user={current_user}&api_key={key}&format=json&page=1').text)\n",
    "            user_tops = user_tops['topartists']['artist']\n",
    "            if not user_tops:\n",
    "                print('User had no top artists.')\n",
    "                no_artist_users.add(current_user)\n",
    "                if len(no_artist_users) % 10 == 0:\n",
    "                    with open('no_artist_users.txt', 'w') as file:\n",
    "                        file.write(repr(no_artist_users))\n",
    "                pass # Don't add users with no top artists\n",
    "            else:\n",
    "                user_rows = [{'user': current_user, 'artist_name': row['name'], 'play_count': row['playcount'], 'artist_url': row['url']} for row in user_tops]\n",
    "                rows_to_add += user_rows\n",
    "                df_user_set.add(current_user)\n",
    "                print('Logged user!')\n",
    "\n",
    "                if len(rows_to_add) > 10000:\n",
    "                    print(f'++++++++++++Logging... ({user_df.shape[0] + len(rows_to_add)} rows)')\n",
    "                    user_df = pd.concat([user_df, pd.DataFrame(rows_to_add)])\n",
    "                    rows_to_add = []\n",
    "                    with open('user-df.csv', 'w', encoding='utf-8') as file:\n",
    "                        file.write(user_df.to_csv())\n",
    "                    \n",
    "                \n",
    "        except KeyError:\n",
    "            no_artist_users.add(current_user)\n",
    "            print('------------------', user_tops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5f0261d-28c7-4989-b267-46d0fc2461e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_df_file_location = '' # Replace with file location of df of user info saved from previous step\n",
    "user_df = pd.read_csv(user_df_file_location)[['user', 'artist_name', 'play_count', 'artist_url']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0198585-6626-44c8-a4cb-e11c3dd82f7a",
   "metadata": {},
   "source": [
    "Now we have to pull the dataset of artist nationalities. Last.fm's API does not provide this information. However, it does provide the ids of its artists on the site musicbrainz, which in turn has the information we need. In order to use their API, we have to specify a user agent, consisting of an app name and a contact email. For example, with the app name Service and the contact email service@mail.com, our agent would be: Service ( service@mail.com )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e33590-0087-46af-a02a-e42197d546c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "mb_user_agent = '' # Add your user agent here\n",
    "mb_headers = {\n",
    "    'User-Agent': mb_user_agent\n",
    "}\n",
    "\n",
    "\n",
    "artists = user_df['artist_name'].unique()\n",
    "with open('artists_info_backups/artists_info_2024-02-02 10_23_02.292744.json', 'r', encoding='utf-8') as file:\n",
    "    artists_info = json.load(file)\n",
    "with open('artists_info_backups/no_info_2024-02-02 10_23_12.465961.json', 'r', encoding='utf-8') as file:\n",
    "    no_info_artists = set(json.load(file))\n",
    "with open('artists_info_backups/strange_error_2024-02-02 10_23_12.558135.json', 'r', encoding='utf-8') as file:\n",
    "    strange_error_artists = json.load(file)\n",
    "\n",
    "for artist in artists: \n",
    "    if artist not in artists_info and artist not in no_info_artists and artist not in strange_error_artists and type(artist) is str:\n",
    "        sleep(0.2)\n",
    "        artist = artist.replace('&', 'and')\n",
    "        if not (artist not in artists_info and artist not in no_info_artists and artist not in strange_error_artists and type(artist) is str):\n",
    "            pass\n",
    "        print(artist)\n",
    "        try:\n",
    "            artist_req = requests.get(f'http://ws.audioscrobbler.com/2.0/?method=artist.getinfo&artist={artist}&api_key={key}&format=json&page=1').json()\n",
    "        except ValueError as e:\n",
    "            \n",
    "            print(f'+++++++++++Strange new error: {e}')\n",
    "            strange_error_artists[artist] = str(e)\n",
    "            if len(strange_error_artists) % 5 == 0:\n",
    "                with open('strange_error_test.json', 'w', encoding='utf-8') as file:\n",
    "                    json.dump(strange_error_artists, file)\n",
    "                with open('strange_error_test.json', 'r', encoding='utf-8') as file:\n",
    "                    data_loader = json.load(file)\n",
    "                    if len(data_loader) < len(strange_error_artists) - 2:\n",
    "                        raise Exception('JSON WRITE ERROR')\n",
    "                    strange_error_artists = data_loader\n",
    "        try:\n",
    "            artist_mbid= artist_req['artist']['mbid']\n",
    "            artist_request = requests.get(f'https://musicbrainz.org/ws/2/artist/{artist_mbid}?fmt=json', headers=mb_headers)\n",
    "            artist_info = artist_request.json()\n",
    "            artists_info[artist] = artist_info\n",
    "            \n",
    "            if len(artists_info) % 100 == 0:\n",
    "                with open('artists_info_test.json', 'w', encoding='utf-8') as file:\n",
    "                    json.dump(artists_info, file)\n",
    "                with open('artists_info_test.json', 'r', encoding='utf-8') as file:\n",
    "                    data_loader = json.load(file)\n",
    "                    if len(data_loader) < len(artists_info) - 2:\n",
    "                        raise Exception('JSON WRITE ERROR')\n",
    "                    artists_info = data_loader\n",
    "                    \n",
    "            # Save backups\n",
    "            if len(artists_info) % 5000 == 0:\n",
    "                print(len(artists_info))\n",
    "                with open(f'artists_info_backups/artists_info_{str(datetime.now())}.json'.replace(':', '_'), 'w') as file:\n",
    "                    json.dump(artists_info, file)\n",
    "                with open(f'artists_info_backups/no_info_{str(datetime.now())}.json'.replace(':', '_'), 'w', encoding='utf-8') as file:\n",
    "                    json.dump(list(no_info_artists), file)\n",
    "                with open(f'artists_info_backups/strange_error_{str(datetime.now())}.json'.replace(':', '_'), 'w', encoding='utf-8') as file:\n",
    "                    json.dump(strange_error_artists, file)\n",
    "                    \n",
    "        except KeyError as k:\n",
    "            if str(k) == \"'mbid'\":\n",
    "                print('No mbid found!')\n",
    "                no_info_artists.add(artist)\n",
    "                if len(no_info_artists) % 30 == 0:\n",
    "                    with open('no_info_test.json', 'w', encoding='utf-8') as file:\n",
    "                        json.dump(list(no_info_artists), file)\n",
    "                    with open('no_info_test.json', 'r', encoding='utf-8') as file:\n",
    "                        data_loader = json.load(file)\n",
    "                        if len(data_loader) < len(no_info_artists) - 2:\n",
    "                            raise Exception('JSON WRITE ERROR')\n",
    "                        no_info_artists = set(data_loader)\n",
    "            else:\n",
    "                print(f'+++++++++++Strange new error: {k}')\n",
    "                strange_error_artists[artist] = str(k)\n",
    "                if len(strange_error_artists) % 5 == 0:\n",
    "                    with open('strange_error_test.json', 'w', encoding='utf-8') as file:\n",
    "                        json.dump(strange_error_artists, file)\n",
    "                    with open('strange_error_test.json', 'r', encoding='utf-8') as file:\n",
    "                        data_loader = json.load(file)\n",
    "                        if len(data_loader) < len(strange_error_artists) - 2:\n",
    "                            raise Exception('JSON WRITE ERROR')\n",
    "                        strange_error_artists = data_loader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
